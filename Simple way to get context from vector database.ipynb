{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "165c9979",
   "metadata": {},
   "source": [
    "# Simple Way to Get Context from Vector Database\n",
    "This notebook demonstrates how to retrieve contextual information from a vector database. Vector databases are used to store and query high-dimensional vectors, which are often derived from text. The notebook covers the following steps:\n",
    "\n",
    "\n",
    "1. Connecting to the Vector Database: Code to establish a connection to the vector database.\n",
    "2. Embedding query: Code to use OCIGenAIEmbeddings to generate a vector from a query\n",
    "2. Querying the Database: Techniques for querying the database to retrieve relevant context based on input vectors.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65f6016e-2e12-4247-a386-3cd4acc55623",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings.oci_generative_ai import OCIGenAIEmbeddings\n",
    "from langchain_community.vectorstores import OracleVS\n",
    "import oracledb\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2937a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context_by_query():\n",
    "    \"\"\"\n",
    "    Retrieves context by performing a similarity search using a query embedding.\n",
    "    This function performs the following steps:\n",
    "    1. Loads environment variables from a .env file.\n",
    "    2. Initializes the OCI embedding service using the loaded environment variables.\n",
    "    3. Connects to an Oracle Autonomous Database using the loaded environment variables.\n",
    "    4. Creates an embedding for a predefined query.\n",
    "    5. Initializes a vector store with the database connection, embeddings, and table name.\n",
    "    6. Performs a similarity search using the query embedding to retrieve the top results.\n",
    "    Returns:\n",
    "        list: A list of top results based on the similarity search.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load environment variables from a .env file\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    #OCI embedding service\n",
    "    embeddings =  OCIGenAIEmbeddings(\n",
    "        model_id=os.getenv('CON_GEN_AI_EMB_MODEL_ID'),\n",
    "        service_endpoint=os.getenv('CON_GEN_AI_SERVICE_ENDPOINT'),\n",
    "        compartment_id=os.getenv('CON_GEN_AI_COMPARTMENT_ID')\n",
    "        )\n",
    "\n",
    "    # Connect to Oracle Autonomous Database\n",
    "    conn = oracledb.connect(\n",
    "        user=os.getenv('CON_ADB_DEV_USER_NAME'), \n",
    "        password=os.getenv('CON_ADB_DEV_PASSWORD'), \n",
    "        dsn=os.getenv('CON_ADB_DEV_SERVICE_NAME')\n",
    "        )\n",
    "\n",
    "    #query\n",
    "    query = [\"Retrieval Augmented Generation (RAG), Large Language Models (LLMs)\"]\n",
    "    # create query embedding \n",
    "    query_embedding = embeddings.embed_documents(query)\n",
    "\n",
    "    #table containing embeddings\n",
    "    table_name = \"DOCS\"\n",
    "\n",
    "    #create vector store\n",
    "    vector_store = OracleVS(conn, embeddings, table_name)\n",
    "\n",
    "    #get context\n",
    "    results = vector_store.similarity_search_by_vector(embedding=query_embedding[0], \n",
    "        k=10  # Number of top results to retrieve\n",
    "    )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a72437ec-2b09-4bad-aff0-330cdeeec25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1:\n",
      "ID: 13\n",
      "ID: {'file_id': 13, 'file_trg_obj_name': 'None', 'file_version': 1, 'file_date': '2025-01-21 18:34:42', 'obj_name': 'None'}\n",
      "ID: Keywords: Retrieval Augmented Generation (RAG), Large Language Models\n",
      "(LLMs), Generative AI in Software Development, Transparent AI.\n",
      "1\n",
      "Introduction\n",
      "Large language models (LLMs) excel at generating human like responses, but\n",
      "base AI models can't keep up with the constantly evolving information within\n",
      "dynamic sectors. They rely on static training data, leading to outdated or incom-\n",
      "plete answers. Thus they often lack transparency and accuracy in high stakes\n",
      "arXiv:2410.15944v1 [cs.SE] 21 Oct 2024\n",
      "decision making. Retrieval Augmented Generation (RAG) presents a powerful\n",
      "solution to this problem. RAG systems pull in information from external data\n",
      "sources, like PDFs, databases, or websites, grounding the generated content in\n",
      "------------------------------------------------------------\n",
      "Result 2:\n",
      "ID: 13\n",
      "ID: {'file_id': 13, 'file_trg_obj_name': 'None', 'file_version': 1, 'file_date': '2025-01-21 18:34:42', 'obj_name': 'None'}\n",
      "ID: tegrating two core components of NLP: Information Retrieval (IR) and Natural\n",
      "Language Generation (NLG). The RAG framework, first introduced by Lewis\n",
      "et al.[5] combines dense retrieval methods with large scale generative models to\n",
      "produce responses that are both contextually relevant and factually accurate.\n",
      "By explicitly retrieving relevant passages from a large corpus and augmenting\n",
      "this information in the generation process, RAG models enhance the factual\n",
      "grounding of their outputs from the up-to-date knowledge.\n",
      "A generic workflow of Retrieval Augmented Generation (RAG) system, show-\n",
      "casing how it fundamentally enhances the capabilities of Large Language Models\n",
      "(LLMs) by grounding their outputs in real-time, relevant information is illus-\n",
      "trated in the Fig[1]. Unlike static models which generate responses based only\n",
      "------------------------------------------------------------\n",
      "Result 3:\n",
      "ID: 13\n",
      "ID: {'file_id': 13, 'file_trg_obj_name': 'None', 'file_version': 1, 'file_date': '2025-01-21 18:34:42', 'obj_name': 'None'}\n",
      "ID: Developing Retrieval Augmented Generation\n",
      "(RAG) based LLM Systems from PDFs: An\n",
      "Experience Report\n",
      "Ayman Asad Khan\n",
      "Tampere University\n",
      "ayman.khan@tuni.fi\n",
      "Md Toufique Hasan\n",
      "Tampere University\n",
      "mdtoufique.hasan@tuni.fi\n",
      "Kai Kristian Kemell\n",
      "Tampere University\n",
      "kai-kristian.kemell@tuni.fi\n",
      "Jussi Rasku\n",
      "Tampere University\n",
      "jussi.rasku@tuni.fi\n",
      "Pekka Abrahamsson\n",
      "Tampere University\n",
      "pekka.abrahamsson@tuni.fi\n",
      "Abstract. This paper presents an experience report on the develop-\n",
      "ment of Retrieval Augmented Generation (RAG) systems using PDF\n",
      "documents as the primary data source. The RAG architecture combines\n",
      "generative capabilities of Large Language Models (LLMs) with the preci-\n",
      "sion of information retrieval. This approach has the potential to redefine\n",
      "how we interact with and augment both structured and unstructured\n",
      "------------------------------------------------------------\n",
      "Result 4:\n",
      "ID: 13\n",
      "ID: {'file_id': 13, 'file_trg_obj_name': 'None', 'file_version': 1, 'file_date': '2025-01-21 18:34:42', 'obj_name': 'None'}\n",
      "ID: (LLM) with both established and emerging information.\n",
      "6. Generation of Response by LLM:\n",
      "The context-infused prompt, consisting of the original user query combined\n",
      "with the retrieved relevant content is provided to a Large Language Model\n",
      "(LLM) like GPT, T5 or Llama. The LLM then processes this augmented in-\n",
      "put to generate a coherent response not only fluent but factually grounded.\n",
      "7. Final Output:\n",
      "By moving beyond the opaque outputs of traditional models, the final output\n",
      "of RAG systems offer several advantages: they minimize the risk of generating\n",
      "hallucinations or outdated information, enhance interpretability by clearly\n",
      "linking outputs to real-world sources, enriched with relevant and accurate\n",
      "responses.\n",
      "The RAG model framework introduces a paradigm shift in Generative AI by\n",
      "------------------------------------------------------------\n",
      "Result 5:\n",
      "ID: 13\n",
      "ID: {'file_id': 13, 'file_trg_obj_name': 'None', 'file_version': 1, 'file_date': '2025-01-21 18:34:42', 'obj_name': 'None'}\n",
      "ID: ities. Incorporating cross-lingual retrieval and multimodal data processing\n",
      "can make RAG models more versatile and applicable to a wider range of\n",
      "global and multimedia tasks[2].\n",
      "Future research will likely focus on enhancing their adaptability, cross-lingual\n",
      "capabilities, and integration with diverse data sources to address increasingly\n",
      "complex information needs.\n",
      "7\n",
      "Conclusions\n",
      "The development of Retrieval Augmented Generation (RAG) systems offers a\n",
      "new way to improve large language models by grounding their outputs in real-\n",
      "time, relevant information. This paper covers the main steps for building RAG\n",
      "systems that use PDF documents as the data source. With clear examples and\n",
      "code snippets, it connects theory with practice and highlights challenges like\n",
      "handling complex PDFs and extracting useful text. It also looks at the options\n",
      "------------------------------------------------------------\n",
      "Result 6:\n",
      "ID: 13\n",
      "ID: {'file_id': 13, 'file_trg_obj_name': 'None', 'file_version': 1, 'file_date': '2025-01-21 18:34:42', 'obj_name': 'None'}\n",
      "ID: (GPT Series) and an open-source Large Language Model (LLM)\n",
      "Llama and thus divided into two subsections[4.2.1][4.2.2]. The objective is to\n",
      "equip developers with the knowledge and practical steps necessary to implement\n",
      "RAG systems effectively, while highlighting common mistakes and best practices\n",
      "at each stage of the process. Each subsection is designed to provide practical\n",
      "insights into setup, development, integration, customization and optimization to\n",
      "generate well-grounded and aligned outputs.\n",
      "In addition to the two primary approaches discussed in this guide there are\n",
      "several alternative frameworks and methodologies for developing Retrieval Aug-\n",
      "mented Generation (RAG) systems. Each of these options such as Cohere, AI21's\n",
      "------------------------------------------------------------\n",
      "Result 7:\n",
      "ID: 13\n",
      "ID: {'file_id': 13, 'file_trg_obj_name': 'None', 'file_version': 1, 'file_date': '2025-01-21 18:34:42', 'obj_name': 'None'}\n",
      "ID: 2.2.2\n",
      "RAG: Dynamic Information and Large Knowledge Bases Retrieval-\n",
      "Augmented Generation (RAG) combines LLMs with a retrieval mechanism that\n",
      "allows the model to access external data sources in real-time, making it suitable\n",
      "for scenarios requiring up-to-date or frequently changing information. RAG sys-\n",
      "tems are valuable for handling vast knowledge bases, where embedding all the\n",
      "information directly into the model would be impractical or impossible.\n",
      "Advantages: RAG is ideal for applications that require access to dynamic\n",
      "information, ensuring responses are grounded in real-time data and minimizing\n",
      "hallucinations. It also provides transparency, as the source of the retrieved in-\n",
      "formation can be linked directly.\n",
      "Drawbacks: RAG requires complex infrastructure, including vector databases\n",
      "------------------------------------------------------------\n",
      "Result 8:\n",
      "ID: 13\n",
      "ID: {'file_id': 13, 'file_trg_obj_name': 'None', 'file_version': 1, 'file_date': '2025-01-21 18:34:42', 'obj_name': 'None'}\n",
      "ID: best suites their use case.\n",
      "2\n",
      "Background\n",
      "This section presents the theoretical background of this study. Traditional gen-\n",
      "erative models, such as GPT, BERT, or T5 are trained on massive datasets but\n",
      "have a fixed internal knowledge cut off based on their training data. They can\n",
      "only generate black box answers based on what they know, and this limitation\n",
      "is notable in fields where information changes rapidly and better explainabil-\n",
      "ity and traceability of responses is required, such as healthcare, legal analysis,\n",
      "customer service, or technical support.\n",
      "2.1\n",
      "What is RAG?\n",
      "The concept of Retrieval Augmented Generation (RAG) models is built on in-\n",
      "tegrating two core components of NLP: Information Retrieval (IR) and Natural\n",
      "------------------------------------------------------------\n",
      "Result 9:\n",
      "ID: 13\n",
      "ID: {'file_id': 13, 'file_trg_obj_name': 'None', 'file_version': 1, 'file_date': '2025-01-21 18:34:42', 'obj_name': 'None'}\n",
      "ID: and Learning Systems, 34(9):2115-2130, 2023.\n",
      "8. Chenyan Xiong, Zhuyun Dai, Jamie Callan, and Jie Liu. Knowledge-enhanced lan-\n",
      "guage models for information retrieval and beyond. IEEE Transactions on Knowl-\n",
      "edge and Data Engineering, 36(5):1234-1247, 2024.\n",
      "35\n",
      "Appendix\n",
      "1. Tampere University, \"Cost Estimation for RAG Application Using GPT-4o\",\n",
      "Zenodo, Sep. 2024. doi: 10.5281/zenodo.13740032.\n",
      "36\n",
      "------------------------------------------------------------\n",
      "Result 10:\n",
      "ID: 13\n",
      "ID: {'file_id': 13, 'file_trg_obj_name': 'None', 'file_version': 1, 'file_date': '2025-01-21 18:34:42', 'obj_name': 'None'}\n",
      "ID: accuracy. The guide provides users clear, actionable steps to integrate RAG into\n",
      "their workflows, contributing to the growing toolkit of AI driven solutions.\n",
      "With that, RAG also opens new research avenues that can shape the future\n",
      "of AI and NLP technologies. As these models and tools improve, there are many\n",
      "potential areas for growth, such as finding better ways to search for information,\n",
      "adapting to new data automatically, and handling more than just text (like\n",
      "images or audio). Recent advancements in tools and technologies have further\n",
      "accelerated the development and deployment of RAG models. As RAG models\n",
      "continue to evolve, several emerging trends are shaping the future of this field.\n",
      "1. Haystack: An open-source framework that integrates dense and sparse re-\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "results = get_context_by_query()\n",
    "#print context\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"Result {i + 1}:\")\n",
    "    print(f\"ID: {result.metadata['file_id']}\")\n",
    "    print(f\"ID: {result.metadata}\")\n",
    "    print(f\"ID: {result.page_content}\")\n",
    "    print(\"-\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

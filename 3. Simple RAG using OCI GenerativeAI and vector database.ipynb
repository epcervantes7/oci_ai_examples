{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38c6f302",
   "metadata": {},
   "source": [
    "# Simple Chat using OCI Generative AI\n",
    "\n",
    "The notebook sets up a simple chat application using Oracle Cloud Infrastructure (OCI) Generative AI services. Here's an overview of the entire notebook:\n",
    "\n",
    "1. Imports and Environment Setup:\n",
    "\n",
    "    - Imports necessary libraries such as os, ads, oracledb, dotenv, and oci_genai.\n",
    "    - Loads environment variables from a .env file using load_dotenv().\n",
    "\n",
    "2. Embeddings Initialization:\n",
    "\n",
    "    - Creates an instance of OCIGenAIEmbeddings using environment variables for model ID, service endpoint, and compartment ID.\n",
    "\n",
    "3. Database Connection:\n",
    "\n",
    "    - Establishes a connection to an Oracle database using oracledb.connect() with credentials retrieved from environment variables.\n",
    "\n",
    "4. Vector Store Setup:\n",
    "\n",
    "    - Defines the table name \"MY_DOCS\" as knowledge base.\n",
    "    - Initializes the OracleVS vector store with the database connection, embeddings, and table name.\n",
    "\n",
    "1. Retriever Setup:\n",
    "\n",
    "    - Converts the vector store into a retriever using vector_store.as_retriever().\n",
    "\n",
    "2. Prompt Template Definition:\n",
    "\n",
    "    - Defines a prompt template for the RAG model to use when generating answers.\n",
    "    - The template instructs the assistant to use retrieved context fragments to answer questions.\n",
    "\n",
    "3. Chat Model Initialization:\n",
    "\n",
    "    - Creates an instance of ChatOCIGenAI with specified parameters, including model ID, service endpoint, compartment ID, and other model settings.\n",
    "\n",
    "4. RAG Model Setup:\n",
    "\n",
    "    - Combines the chat model and retriever into a RetrievalQA model using RetrievalQA.from_chain_type().\n",
    "    - Uses the defined prompt template for generating answers.\n",
    "\n",
    "5. Example Usage:\n",
    "\n",
    "    - Demonstrates how to use the RAG model to generate responses to user inputs.\n",
    "    - Sends a prompt to the model and prints the generated response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97b44c7f-4e95-48c7-a2ef-8ef502d49ccf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T18:40:06.993545Z",
     "iopub.status.busy": "2025-01-23T18:40:06.993228Z",
     "iopub.status.idle": "2025-01-23T18:40:10.409534Z",
     "shell.execute_reply": "2025-01-23T18:40:10.407946Z",
     "shell.execute_reply.started": "2025-01-23T18:40:06.993521Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import oracledb\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.chat_models.oci_generative_ai import ChatOCIGenAI\n",
    "from langchain_community.embeddings.oci_generative_ai import OCIGenAIEmbeddings\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.vectorstores import OracleVS\n",
    "import oracledb\n",
    "\n",
    "load_dotenv()\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36b810f7-85e6-4cc4-a6e3-cfcb077e8547",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T18:46:19.787233Z",
     "iopub.status.busy": "2025-01-23T18:46:19.786583Z",
     "iopub.status.idle": "2025-01-23T18:46:22.852593Z",
     "shell.execute_reply": "2025-01-23T18:46:22.851250Z",
     "shell.execute_reply.started": "2025-01-23T18:46:19.787213Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "default_path=\"\"\n",
    "AUTH_TYPE = \"API_KEY\"\n",
    "CONFIG_PROFILE = \"DEFAULT\"\n",
    "embeddings = OCIGenAIEmbeddings(\n",
    "            model_id=os.getenv('CON_GEN_AI_EMB_MODEL_ID'),\n",
    "            service_endpoint=os.getenv('CON_GEN_AI_SERVICE_ENDPOINT'),\n",
    "            compartment_id=os.getenv('CON_GEN_AI_COMPARTMENT_ID'),\n",
    "            truncate=\"NONE\",\n",
    "            auth_file_location=default_path+\"oci/config\",\n",
    "            auth_type=AUTH_TYPE,\n",
    "            auth_profile=CONFIG_PROFILE\n",
    "        )\n",
    "\n",
    "\n",
    "default_path = \"\"\n",
    "connection = oracledb.connect(\n",
    "    user=os.getenv('CON_ADB_DEV_USER_NAME'), \n",
    "    password=os.getenv('CON_ADB_DEV_PASSWORD'), \n",
    "    dsn=os.getenv('CON_ADB_DEV_SERVICE_NAME'),\n",
    "    config_dir=default_path+\"oci\",\n",
    "    wallet_location=default_path+\"oci\",\n",
    "    wallet_password=os.getenv('DB_WALLET_PASSWORD')\n",
    "    )\n",
    "\n",
    "\n",
    "#vector store table name\n",
    "table_name = \"MY_DOCS\"\n",
    "\n",
    "vector_store = OracleVS(connection, embeddings, table_name)\n",
    "\n",
    "\n",
    "retriever = vector_store.as_retriever(\n",
    "    # search_kwargs={ 'k': 100} <- parameter to define the number of documents to retrieve\n",
    ")\n",
    "\n",
    "rag_prompt_template = \"\"\"You are an assistant for question-answering tasks.\n",
    "            Please use only the following retrieved context fragments to answer the question.\n",
    "            If you don't know the answer, say you the cuestion is out of my context.\n",
    "            Always use all available data.:\n",
    "            {context}\n",
    "            Question: {question}\n",
    "            \"\"\"\n",
    "\n",
    "rag_prompt = PromptTemplate.from_template(rag_prompt_template)\n",
    "\n",
    "\n",
    "llm = ChatOCIGenAI(\n",
    "        model_id         = os.getenv(\"CON_GEN_AI_CHAT_MODEL_ID\"),\n",
    "        service_endpoint = os.getenv(\"CON_GEN_AI_SERVICE_ENDPOINT\"),\n",
    "        compartment_id   = os.getenv(\"CON_GEN_AI_COMPARTMENT_ID\"),\n",
    "        provider         = \"meta\",\n",
    "        is_stream        = True,\n",
    "        auth_type        = os.getenv(\"CON_GEN_AI_AUTH_TYPE\"),\n",
    "        model_kwargs     = {\n",
    "            \"max_tokens\"        : 1024,\n",
    "            \"temperature\"       : 0.6,\n",
    "            \"top_p\"             : 0.7,\n",
    "            \"top_k\"             : 20,\n",
    "            \"frequency_penalty\" : 0\n",
    "        }\n",
    "    )\n",
    "\n",
    "rag = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": rag_prompt}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d107690-b64b-4e95-b5be-5ede7ed13b64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T18:46:34.506934Z",
     "iopub.status.busy": "2025-01-23T18:46:34.506620Z",
     "iopub.status.idle": "2025-01-23T18:47:27.066048Z",
     "shell.execute_reply": "2025-01-23T18:47:27.064558Z",
     "shell.execute_reply.started": "2025-01-23T18:46:34.506917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'what is Oracle AI Vector Search?', 'result': 'Oracle AI Vector Search is designed for Artificial Intelligence (AI) workloads and allows you to query data based on semantics, rather than keywords. It stores vector embeddings, which are mathematical vector representations of data points, and these vector embeddings describe the semantic meaning behind content such as words, documents, audio tracks, or images.'}\n"
     ]
    }
   ],
   "source": [
    "print(rag.invoke(\"what is Oracle AI Vector Search?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a11de710-3994-4caa-9a66-6964f379e081",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T18:41:47.191013Z",
     "iopub.status.busy": "2025-01-23T18:41:47.190737Z",
     "iopub.status.idle": "2025-01-23T18:41:49.403515Z",
     "shell.execute_reply": "2025-01-23T18:41:49.402482Z",
     "shell.execute_reply.started": "2025-01-23T18:41:47.190996Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'Can you talk about peruvian food?', 'result': 'The question is out of my context.'}\n"
     ]
    }
   ],
   "source": [
    "print(rag.invoke(\"Can you talk about peruvian food?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "entel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
